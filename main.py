# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-gvRCiRWXcZUlwEPOVd-G_yNZ5q_q3Kv
"""

from langchain_openai import AzureChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from dotenv import load_dotenv
import os
from executive import graph, state

load_dotenv()

llm_chat_client = AzureChatOpenAI(
    azure_deployment=os.getenv("OPENAI_DEPLOYMENT_NAME_8K"),
    api_version=os.getenv("OPENAI_API_VERSION"),
    api_key=os.getenv("OPENAI_API_KEY"),
    azure_endpoint=os.getenv("AZURE_ENDPOINT"),
    temperature=0,
    max_tokens=512,
)

def refine_query(goal: str) -> str:
    prompt = (
        f"You are a software engineer. The user goal is:\n"
        f"{goal}\n\n"
        f"Return only a concise search query (like Search and return relevant code snippets that are to be migrated). "
        f"that will help find the relevant code snippets."
    )
    response = llm_chat_client.invoke([
        SystemMessage(content="You refine goals into precise search queries."),
        HumanMessage(content=prompt)
    ])
    return response.content.strip()

def main():
    high_level_goal = "Migrate the payroll system and ensure it's fully functional."
    print(f"[Main] Received goal: {high_level_goal}")

    # Step 1: Refine into query
    search_query = refine_query(high_level_goal)
    print(f"[Main] Refined query: {search_query}")

    # Step 2: Inject query into state
    state["query"] = search_query
    print("Passing control to executive LangGraph")
    # Step 3: Run executive workflow
    final_state = graph.invoke(state)
    print("\n[Main] Workflow finished. Final state:")
    print(final_state)

if __name__ == "__main__":
    main()